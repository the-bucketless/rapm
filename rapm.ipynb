{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rapm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO/VFemuXbQJ4Mhop8w1LDZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/the-bucketless/rapm/blob/main/rapm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKlGVNnG1oRu"
      },
      "source": [
        "# 5-on-5 Corsi-Based RAPM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VCVZU7kpbeO"
      },
      "source": [
        "The data is provided by [Harry Shomer](https://twitter.com/offsides_review).  Send him some love.  If the site is no longer up when you're looking at this, you can scrape the data with [his scraper](https://github.com/HarryShomer/Hockey-Scraper).\r\n",
        "\r\n",
        "I've run this on every season to date (up to 2019/20 for full seasons and a partial 2020/21) and haven't noticed issues.  If you find something awry, let me know.  \r\n",
        "  \r\n",
        "I've made an effort to over-comment the code to try to help anyone new understand what's going on.\r\n",
        "\r\n",
        "Feel free to use this as you see fit, but if you're doing something outside of personal use, keep it open source."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtENPs9fpXHG"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from scipy.sparse import csr_matrix\r\n",
        "from sklearn.linear_model import Ridge, RidgeCV\r\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\r\n",
        "from sklearn.preprocessing import MultiLabelBinarizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPtcHsC0D92W"
      },
      "source": [
        "Enter the season you want to use.  It needs to be the full first year followed by the full second year of the season, even if there weren't any games in the first year.  The earliest season available is 2007/08."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNl2jt6ldQSe"
      },
      "source": [
        "season = \"20192020\" #@param {type: \"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q30HjEYcILJ"
      },
      "source": [
        "pbp_url = f\"https://hockey-data.harryshomer.com/pbp/nhl_pbp{season}.csv.gz\"\r\n",
        "pbp = pd.read_csv(pbp_url, compression=\"gzip\")\r\n",
        "\r\n",
        "shifts_url = f\"https://hockey-data.harryshomer.com/shifts/nhl_shifts{season}.csv.gz\"\r\n",
        "shifts = pd.read_csv(shifts_url, compression=\"gzip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tg9xG2N59AP"
      },
      "source": [
        "## Setting up the play-by-play dataframe\r\n",
        "\r\n",
        "Events included in this RAPM are from regular season games at 5-on-5.  If you'd like to include playoff games, make sure you still remove shootouts from regular season games.  Leaving them in causes some issues.\r\n",
        "\r\n",
        "The way things are set up, teams are allowed to have more than 5 skaters on the ice (this can be caused by teams trying to get too many men penalties or issues in how things were recorded) so long as both teams have a goalie on the ice.  It can also result in the odd powerplay event finding its way into the data if both teams have 5 or more skaters listed as being on the ice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm4mREVceB2_"
      },
      "source": [
        "venues = (\"away\", \"home\")\r\n",
        "corsi_events = (\"GOAL\", \"SHOT\", \"MISS\", \"BLOCK\")\r\n",
        "\r\n",
        "# converting column names to snake case (personal preference)\r\n",
        "pbp.rename(columns={c: c.lower() for c in pbp.columns}, inplace=True)\r\n",
        "\r\n",
        "# need to track who's a goalie for when we add in the shift changes\r\n",
        "goalies = set([x for x in pd.unique(pbp[[\"away_goalie\", \"home_goalie\"]].values.ravel()) if x == x])\r\n",
        "\r\n",
        "# score state ranges from -3 to 3, away score state won't be needed until much later\r\n",
        "pbp[\"home_score_state\"] = (pbp.home_score - pbp.away_score).clip(lower=-3, upper=3)\r\n",
        "\r\n",
        "# only keep columns that will be used\r\n",
        "# you may want to include more if you're adding features\r\n",
        "pbp = pbp[[\"game_id\", \"period\", \"event\", \"seconds_elapsed\", \"home_score_state\",\r\n",
        "           \"home_zone\", \"ev_team\", \"away_team\", \"home_team\"]]\r\n",
        "\r\n",
        "# removing playoff games, shootouts, and events that won't factor in\r\n",
        "pbp = pbp.loc[(pbp.game_id < 30000) & (pbp.period < 5) & (pbp.event.isin([\"FAC\", *corsi_events]))]\r\n",
        "\r\n",
        "# convert seconds_elapsed to be relative to game instead of period\r\n",
        "pbp.seconds_elapsed += (pbp.period - 1) * 1200\r\n",
        "\r\n",
        "# corsi\r\n",
        "pbp[\"corsi\"] = (pbp.event.isin(corsi_events)).astype(int)\r\n",
        "pbp[\"away_corsi\"] = pbp.corsi * (pbp.away_team == pbp.ev_team)\r\n",
        "pbp[\"home_corsi\"] = pbp.corsi * (pbp.home_team == pbp.ev_team)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUQowkZd6FJT"
      },
      "source": [
        "## Setting up the shift dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RskiW27gDMR"
      },
      "source": [
        "# more snake case\r\n",
        "shifts.rename(columns={c: c.lower() for c in shifts.columns}, inplace=True)\r\n",
        "\r\n",
        "# get rid of nonsense\r\n",
        "shifts.dropna(inplace=True)\r\n",
        "shifts = shifts.loc[(shifts.game_id < 30000) & (shifts.start < shifts.end)]\r\n",
        "\r\n",
        "# convert times to be relative to game instead of period\r\n",
        "shifts[\"start\"] += (shifts[\"period\"] - 1) * 1200\r\n",
        "shifts[\"end\"] += (shifts[\"period\"] - 1) * 1200\r\n",
        "\r\n",
        "# add away and home team from play-by-play\r\n",
        "teams_by_venue = pbp.groupby(by=\"game_id\", as_index=False)[[\"away_team\", \"home_team\"]].first()\r\n",
        "shifts = shifts.merge(teams_by_venue, how=\"left\", on=\"game_id\")\r\n",
        "\r\n",
        "# separate players by venue\r\n",
        "shifts[\"away_player\"] = np.where(shifts.team == shifts.away_team, shifts.player, np.nan)\r\n",
        "shifts[\"home_player\"] = np.where(shifts.team == shifts.home_team, shifts.player, np.nan)\r\n",
        "\r\n",
        "# create list of all players, this doesn't get used until the end\r\n",
        "player_list = pd.unique(shifts.player)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD6fKYfP6RIb"
      },
      "source": [
        "## Ch-ch-ch-changes\r\n",
        "\r\n",
        "If you're used to the EvolvingWild twins' scraper, they provide shift starts and ends for you as change events.  The data we're working on doesn't include them, so we have to add them in.  \r\n",
        "  \r\n",
        "This isn't the nicest looking way I've thought to do it, but it is the fastest I've found.  I've tried a lot of different ways thinking there has to be something better than the dreaded for loop, but even when I think I'm being clever, things still run slower.\r\n",
        "\r\n",
        "The first step is to group the shifts by the unique start and end times, including columns for which players stepped on the ice and who stepped off for both teams.  The players for each side are thrown together as a set.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln84PkJ_8H9k"
      },
      "source": [
        "time_dfs = []\r\n",
        "for change in (\"start\", \"end\"):\r\n",
        "    time_dfs.append(shifts.groupby(by=[\"game_id\", change], as_index=False)[[\"away_player\", \"home_player\"]].agg(set))\r\n",
        "\r\n",
        "    # rename time column for easier merging into pbp\r\n",
        "    time_dfs[-1].rename(columns={change: \"seconds_elapsed\"}, inplace=True)\r\n",
        "\r\n",
        "    # track type of change (start or end of shift)\r\n",
        "    time_dfs[-1][\"type\"] = change\r\n",
        "\r\n",
        "# combine start and end shifts into single dataframe and sort everything into place\r\n",
        "changes = pd.concat(time_dfs, ignore_index=True).sort_values(by=[\"game_id\", \"seconds_elapsed\", \"type\"])\r\n",
        "\r\n",
        "for venue in venues:\r\n",
        "    # remove na values from sets\r\n",
        "    changes[f\"{venue}_player\"] = changes[f\"{venue}_player\"].apply(lambda x: {player for player in x if player == player})\r\n",
        "\r\n",
        "    # separate changes by players going on and players going off\r\n",
        "    changes[f\"{venue}_on\"] = np.where(changes[\"type\"] == \"start\", changes[f\"{venue}_player\"], \"\")\r\n",
        "    changes[f\"{venue}_off\"] = np.where(changes[\"type\"] == \"end\", changes[f\"{venue}_player\"], \"\")\r\n",
        "\r\n",
        "# bring players going on and players going off at the same time into single row\r\n",
        "changes = changes.groupby(by=[\"game_id\", \"seconds_elapsed\"], as_index=False).agg({\"away_on\": \"last\", \"away_off\": \"first\",\r\n",
        "                                                                                  \"home_on\": \"last\", \"home_off\": \"first\"})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e6CqKP8sHzM"
      },
      "source": [
        "Then, we loop through every change, keeping track of who's still on the ice using set operations.  For each row, we start with who was on the ice in the previous row, then remove everyone who left the ice, and add anyone starting their shift.  It's important to remove players before adding because the end of one period shares its time with the start of the next.  Goalies will often have shifts from 0 to 1200, 1200 to 2400, etc.  If you add before you remove, the goalie won't be out there to start the 2nd."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-O74mNm8Pms"
      },
      "source": [
        "on_ice_col = {\"away\": [], \"home\": []}    # columns to be added after the for loop\r\n",
        "on_ice = {\"away\": set(), \"home\": set()}    # which players are currently on the ice\r\n",
        "for row in changes.itertuples():\r\n",
        "    for venue in venues:\r\n",
        "        # remove the players going off, then add the players going on\r\n",
        "        on_ice[venue] = on_ice[venue].difference(getattr(row, f\"{venue}_off\")).union(getattr(row, f\"{venue}_on\"))\r\n",
        "        on_ice_col[venue].append(on_ice[venue])\r\n",
        "\r\n",
        "# add to dataframe\r\n",
        "changes[\"away_players\"] = on_ice_col[\"away\"]\r\n",
        "changes[\"home_players\"] = on_ice_col[\"home\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkbOKYtP88Nq"
      },
      "source": [
        "Next, we split the players out of the sets and into their own columns.  Empty net situations are noted and goalies are removed - we don't need RAPM scores for them.  Because more than 5 skaters are allowed to be on the ice, we need to keep the number of home and away columns consistent.  Missing values are replaced with \"dummy\" to allow a future fill function to work properly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6JmyLo18PiG"
      },
      "source": [
        "for venue in venues:\r\n",
        "    # empty net if no one on the ice is a goalie\r\n",
        "    changes[f\"{venue}_empty_net\"] = changes[f\"{venue}_players\"].apply(lambda x: len(x.intersection(goalies)) == 0).astype(int)\r\n",
        "\r\n",
        "    # remove goalies from player list\r\n",
        "    changes[f\"{venue}_players\"] -= goalies\r\n",
        "\r\n",
        "    # split sets into separate columns\r\n",
        "    players = pd.DataFrame(changes[f\"{venue}_players\"].values.tolist()).add_prefix(venue)\r\n",
        "\r\n",
        "    # glue everything together\r\n",
        "    changes = changes.join(players)\r\n",
        "\r\n",
        "# allowing more than 5 skaters on the ice, need to keep the number of home and away columns consistent\r\n",
        "max_away = int(changes.columns[list(changes.columns).index(\"home_empty_net\") - 1][-1])\r\n",
        "max_home = int(changes.columns[-1][-1])\r\n",
        "\r\n",
        "for i in range(max_away, max_home):\r\n",
        "    changes[f\"away{i + 1}\"] = \"dummy\"\r\n",
        "for i in range(max_home, max_away):\r\n",
        "    changes[f\"home{i + 1}\"] = \"dummy\"\r\n",
        "\r\n",
        "# add some columns for the merge\r\n",
        "changes[\"event\"] = \"CHANGE\"\r\n",
        "changes[\"away_corsi\"] = 0\r\n",
        "changes[\"home_corsi\"] = 0\r\n",
        "\r\n",
        "# remove columns that won't survive the merge\r\n",
        "changes.drop(columns=[f\"{venue}_{c}\" for venue in venues for c in (\"on\", \"off\", \"players\")], inplace=True)\r\n",
        "\r\n",
        "# fill all na so they don't interfere with later fillings\r\n",
        "changes.fillna(\"dummy\", inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBfHJnSUtKeo"
      },
      "source": [
        "Finally, we have to make sure things go in the right place.  Changes are considered to be [start time, end time).  That's to say, players are no longer considered to be on the ice when the last second of their shift comes along.  The one exception is if a shot both precedes and occurs at the same time as a faceoff (shot, save, whistle all in the same second).  For those situations, players will be on the ice for the shot, but not the faceoff.  This bit of nonsense accomplishes that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC3Jgc7o24qE"
      },
      "source": [
        "shifted_pbp = pbp.shift(-1)\r\n",
        "pbp[\"sort_code\"] = np.where((shifted_pbp.event == \"FAC\") & (shifted_pbp.seconds_elapsed == pbp.seconds_elapsed), 0, 2)\r\n",
        "changes[\"sort_code\"] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wpbrvf83tbXu"
      },
      "source": [
        "## Merging\r\n",
        "\r\n",
        "Everything's going into a single dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Zh5kvf-xfK0"
      },
      "source": [
        "# add all the changes to the end of the play-by-play dataframe\r\n",
        "pbp = pd.concat([pbp, changes], ignore_index=True)\r\n",
        "\r\n",
        "# sort them into place\r\n",
        "pbp.sort_values(by=[\"game_id\", \"seconds_elapsed\", \"sort_code\"], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJqP_RRoGMJ0"
      },
      "source": [
        "Add a couple features, fill in some missing values, and remove everything we don't need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gDPnuvB3pYO"
      },
      "source": [
        "# track zone starts\r\n",
        "# need zones for home and away teams on faceoffs\r\n",
        "pbp[\"away_zone\"] = np.select([pbp.home_zone == \"Off\", pbp.home_zone == \"Def\"], [\"Def\", \"Off\"], default=\"Neu\")\r\n",
        "\r\n",
        "# zone starts will be the zone of the faceoff until someone changes, then OTF (on-the-fly)\r\n",
        "pbp[\"away_start_zone\"] = np.select([pbp.event == \"FAC\", pbp.event == \"CHANGE\"], [pbp.away_zone, \"OTF\"], default=pd.NA)\r\n",
        "pbp[\"home_start_zone\"] = np.select([pbp.event == \"FAC\", pbp.event == \"CHANGE\"], [pbp.home_zone, \"OTF\"], default=pd.NA)\r\n",
        "\r\n",
        "# fill all na values by pushing things down the dataframe\r\n",
        "pbp.fillna(method=\"ffill\", inplace=True)\r\n",
        "\r\n",
        "# time between events, negative values occur when moving on to the next game\r\n",
        "# these get clipped to 0 and removed with the next line\r\n",
        "pbp[\"duration\"] = (pbp.seconds_elapsed.shift(-1) - pbp.seconds_elapsed).clip(lower=0)\r\n",
        "\r\n",
        "# get rid of anything that doesn't have a corsi value and is of 0 length\r\n",
        "pbp = pbp[(pbp.home_corsi > 0) | (pbp.away_corsi > 0) | (pbp.duration > 0)]\r\n",
        "\r\n",
        "# only using 5-on-5\r\n",
        "pbp = pbp.loc[(pbp.away_empty_net == 0) & (pbp.home_empty_net == 0) \r\n",
        "              & (pbp.away4 != \"dummy\") & (pbp.home4 != \"dummy\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwMC0oo0uICI"
      },
      "source": [
        "## Stints\r\n",
        "\r\n",
        "Group everything into stints.  We have to add up the corsi values and the stint lengths based on any events that have the same features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwxuIDR09HGy"
      },
      "source": [
        "# group by all the features we're using\r\n",
        "stints = pbp.groupby(by=[\"period\", \"away_start_zone\", \"home_start_zone\", \"home_score_state\",\r\n",
        "                         *[c for c in pbp.columns if (\"away\" in c or \"home\" in c) and \"_\" not in c]],\r\n",
        "                     as_index=False, sort=False)\r\n",
        "stints = stints[[\"away_corsi\", \"home_corsi\", \"duration\"]].sum()\r\n",
        "\r\n",
        "# add the away score state for easy use in the upcoming for loop\r\n",
        "stints[\"away_score_state\"] = -stints.home_score_state\r\n",
        "\r\n",
        "# some stints are of length 0 but have corsi events - bump their stint lengths up to 0.5\r\n",
        "stints.duration = stints.duration.clip(lower=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPlFxrW9ue9O"
      },
      "source": [
        "We have to duplicate every stint.  In one case, the away team is considered to be on offense, in the other, the home team is attacking."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzawI0FEBFUH"
      },
      "source": [
        "venue_stints = []\r\n",
        "for venue in venues:\r\n",
        "    def_venue = \"home\" if venue == \"away\" else \"away\"\r\n",
        "\r\n",
        "    venue_stints.append(stints.copy())\r\n",
        "\r\n",
        "    # score state relative the offensive team\r\n",
        "    venue_stints[-1][\"score_state\"] = venue_stints[-1][f\"{venue}_score_state\"]\r\n",
        "\r\n",
        "    # corsi per 60 for the offensive team\r\n",
        "    venue_stints[-1][\"corsi60\"] = venue_stints[-1][f\"{venue}_corsi\"] / venue_stints[-1].duration * 3600\r\n",
        "\r\n",
        "    # remove columns that are no longer needed\r\n",
        "    venue_stints[-1].drop(columns=[\"home_score_state\", \"away_score_state\", \"home_corsi\", \"away_corsi\"], inplace=True)\r\n",
        "\r\n",
        "    # change all columns to be off/def rather than home/away\r\n",
        "    venue_stints[-1].columns = venue_stints[-1].columns.str.replace(venue, \"off\")\r\n",
        "    venue_stints[-1].columns = venue_stints[-1].columns.str.replace(def_venue, \"def\")\r\n",
        "\r\n",
        "    # add a feature for home ice\r\n",
        "    venue_stints[-1][\"is_home\"] = int(venue == \"home\")\r\n",
        "\r\n",
        "# combine away as offense and home as offense into single dataframe\r\n",
        "all_stints = pd.concat(venue_stints, ignore_index=True)\r\n",
        "\r\n",
        "# dummy categorical features (other than players)\r\n",
        "all_stints = pd.get_dummies(data=all_stints, columns=[\"period\", \"off_start_zone\", \"def_start_zone\", \"score_state\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfkYbTPzjVMJ"
      },
      "source": [
        "Now, we dummy the players.  The below relies on the columns of all_stints having all the offensive players first, then the defensive players, then duration.  If you're adding features, make sure this ordering remains (ensure new columns appear after duration)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WunjYvEyHkPP"
      },
      "source": [
        "for side in (\"off\", \"def\"):\r\n",
        "    # these are the columns that immediately follow the offensive player and defensive player columns\r\n",
        "    next_column = \"def0\" if side == \"off\" else \"duration\"\r\n",
        "\r\n",
        "    # get all the player columns for off or def\r\n",
        "    cols = all_stints.loc[:, :next_column].iloc[:, :-1]\r\n",
        "\r\n",
        "    # create dummies\r\n",
        "    mlb = MultiLabelBinarizer(sparse_output=True)\r\n",
        "    players = mlb.fit_transform(cols.astype(str).values)\r\n",
        "    \r\n",
        "    # glue everything together\r\n",
        "    all_stints = all_stints.join(\r\n",
        "        pd.DataFrame.sparse.from_spmatrix(players, index=all_stints.index, \r\n",
        "                                          columns=[f\"{side}_{player}\" for player in mlb.classes_]))\r\n",
        "\r\n",
        "    # get rid of the non-dummied player columns\r\n",
        "    all_stints.drop(columns=cols.columns, inplace=True)\r\n",
        "\r\n",
        "    # don't need the \"dummy\" player variable\r\n",
        "    dummy_col = f\"{side}_dummy\"\r\n",
        "    if dummy_col in all_stints.columns:\r\n",
        "        all_stints.drop(columns=[dummy_col], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikqSFebSvjXW"
      },
      "source": [
        "## RAPM\r\n",
        "\r\n",
        "Convert all_stints into the design matrix (X), targets (y), and weights (w)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9eT2wOVVR8D"
      },
      "source": [
        "y = all_stints.pop(\"corsi60\")\r\n",
        "w = all_stints.pop(\"duration\")\r\n",
        "X = csr_matrix(all_stints.astype(pd.SparseDtype(\"float\", 0.0)).sparse.to_coo())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRC7mDJrvupp"
      },
      "source": [
        "Because sklearn's scoring metrics don't concern themselves with the sample weights of the model, we need to create our own scorer that does."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA1S6fBGdpCb"
      },
      "source": [
        "def mse(y, y_pred, sample_weight=None):\r\n",
        "    if sample_weight is not None:\r\n",
        "        sample_weight = sample_weight.loc[y.index.values].values.reshape(-1)\r\n",
        "    \r\n",
        "    return mean_squared_error(y, y_pred, sample_weight=sample_weight)\r\n",
        "\r\n",
        "mse_scorer = make_scorer(mse, greater_is_better=False, sample_weight=w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhMT0-frkVxy"
      },
      "source": [
        "Time for some cross validation to find the best alpha.  Depending where you look, this parameter may be called lambda, but sklearn calls it alpha.  I've only included three values here so that everything runs fairly quickly.  There's no guarantee any of the three will be all that great, so I'd encourage you to play with this to find something better.  When I train my RAPM model, I use the hyperopt package, but I decided to keep things a little simpler here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlgm--osVX4y"
      },
      "source": [
        "model_cv = RidgeCV(alphas=[25000, 30000, 35000], cv=10, scoring=mse_scorer).fit(X, y, sample_weight=w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-6SNzVQv2PP"
      },
      "source": [
        "The best alpha gets plugged into the final model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlCqF0GQctbR"
      },
      "source": [
        "model = Ridge(alpha=model_cv.alpha_).fit(X, y, sample_weight=w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPlMcQyACPjA"
      },
      "source": [
        "## Scores\r\n",
        "\r\n",
        "All that's left is to look at the scores.  We'll make a dataframe consisting of only the players' scores, though it can be interesting to look at how the other features affect things.  If you add features, make sure you give them names longer than 4 characters for this to work right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elt9I7XmaGEq"
      },
      "source": [
        "rapm = pd.DataFrame({\"player\": [x[4:] for x in all_stints.columns], \r\n",
        "                     \"side\": [x[:3] for x in all_stints.columns], \r\n",
        "                     \"score\": model.coef_})\r\n",
        "\r\n",
        "# separate columns for offense and defense\r\n",
        "rapm[\"off\"] = rapm.score * (rapm.side == \"off\")\r\n",
        "rapm[\"def\"] = rapm.score * (rapm.side == \"def\")\r\n",
        "\r\n",
        "# group each player into their own row\r\n",
        "rapm = rapm.loc[rapm.player.isin(player_list), [\"player\", \"off\", \"def\"]]\r\n",
        "rapm = rapm.groupby(by=\"player\").sum()\r\n",
        "\r\n",
        "# negatives values are good for defense\r\n",
        "rapm[\"total\"] = rapm.off - rapm[\"def\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehWZP9FbwAYA"
      },
      "source": [
        "Let's sort by total RAPM score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "if15o5nXXjwM",
        "outputId": "20727d5a-6806-482e-e070-7b9f2fa050f3"
      },
      "source": [
        "rapm.sort_values(by=\"total\", ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>off</th>\n",
              "      <th>def</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>player</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>VALERI NICHUSHKIN</th>\n",
              "      <td>4.782407</td>\n",
              "      <td>-5.148859</td>\n",
              "      <td>9.931266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TOMAS TATAR</th>\n",
              "      <td>7.554177</td>\n",
              "      <td>-1.891966</td>\n",
              "      <td>9.446143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>JARED SPURGEON</th>\n",
              "      <td>5.060905</td>\n",
              "      <td>-3.493998</td>\n",
              "      <td>8.554903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CRAIG SMITH</th>\n",
              "      <td>6.056402</td>\n",
              "      <td>-2.476526</td>\n",
              "      <td>8.532928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MAX PACIORETTY</th>\n",
              "      <td>5.673644</td>\n",
              "      <td>-2.848287</td>\n",
              "      <td>8.521931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BRETT HOWDEN</th>\n",
              "      <td>-3.443737</td>\n",
              "      <td>4.997895</td>\n",
              "      <td>-8.441632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MAX COMTOIS</th>\n",
              "      <td>-5.276913</td>\n",
              "      <td>3.258515</td>\n",
              "      <td>-8.535428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NIKITA ZAITSEV</th>\n",
              "      <td>-3.386665</td>\n",
              "      <td>5.356667</td>\n",
              "      <td>-8.743331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MARC STAAL</th>\n",
              "      <td>-5.077798</td>\n",
              "      <td>3.746397</td>\n",
              "      <td>-8.824195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LIBOR HAJEK</th>\n",
              "      <td>-5.398953</td>\n",
              "      <td>5.796455</td>\n",
              "      <td>-11.195407</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>883 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        off       def      total\n",
              "player                                          \n",
              "VALERI NICHUSHKIN  4.782407 -5.148859   9.931266\n",
              "TOMAS TATAR        7.554177 -1.891966   9.446143\n",
              "JARED SPURGEON     5.060905 -3.493998   8.554903\n",
              "CRAIG SMITH        6.056402 -2.476526   8.532928\n",
              "MAX PACIORETTY     5.673644 -2.848287   8.521931\n",
              "...                     ...       ...        ...\n",
              "BRETT HOWDEN      -3.443737  4.997895  -8.441632\n",
              "MAX COMTOIS       -5.276913  3.258515  -8.535428\n",
              "NIKITA ZAITSEV    -3.386665  5.356667  -8.743331\n",
              "MARC STAAL        -5.077798  3.746397  -8.824195\n",
              "LIBOR HAJEK       -5.398953  5.796455 -11.195407\n",
              "\n",
              "[883 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqLpDn4WnPKs"
      },
      "source": [
        "This is if you'd like to see a specific player's score.  Note that the name has to exactly match what's in the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wM6MC7Qaa8oa",
        "outputId": "6b4ad57a-7255-4778-9717-a1aca69499a7"
      },
      "source": [
        "player_name = \"SIDNEY CROSBY\" #@param {type: \"string\"}\r\n",
        "rapm.loc[player_name]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "off      3.385302\n",
              "def      2.323679\n",
              "total    1.061623\n",
              "Name: SIDNEY CROSBY, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH_xh4g3bnuU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}